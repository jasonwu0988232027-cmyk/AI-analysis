import streamlit as st

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚é æ¸¬å°ˆå®¶ Pro v3", layout="wide")

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3

# åœç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¼‰å…¥å¿…è¦åº«
try:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import tensorflow as tf
    from sklearn.preprocessing import MinMaxScaler
except ImportError:
    st.error("ç¼ºå°‘å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install gspread oauth2client tensorflow scikit-learn urllib3 certifi")

# --- å…¨å±€è¨­å®š ---
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History" 
BATCH_CD = 1.2 # é˜²æ­¢è¢« yfinance å°é–çš„å»¶é²

# ==================== 1. æ•¸æ“šç²å– (å«è‡ªå‹•æ—¥æœŸé‚è¼¯) ====================

def get_top_100_value_stocks():
    """è‡ªå‹•åˆ¤æ–·æ™‚é–“ï¼šç›¤ä¸­æŠ“æ˜¨æ—¥ï¼Œç›¤å¾ŒæŠ“ä»Šæ—¥ï¼Œå‡æ—¥è‡ªå‹•å¾€å‰æ‰¾"""
    now = datetime.now()
    # è­‰äº¤æ‰€é€šå¸¸åœ¨ 14:30 å¾Œæ‰å®Œæˆç•¶æ—¥çµç®—ï¼Œå»ºè­°è¨­ 15:00 è¼ƒç©©
    if now.hour < 15:
        target_date = now - timedelta(days=1)
    else:
        target_date = now

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    attempts = 0
    data = {}
    while attempts < 7: # æœ€å¤šå¾€å‰æ‰¾ 7 å¤©
        date_str = target_date.strftime('%Y%m%d')
        url = f"https://www.twse.com.tw/exchangeReport/MI_INDEX?response=json&date={date_str}&type=ALLBUT0999"
        
        try:
            res = requests.get(url, headers=headers, timeout=15, verify=False)
            temp_data = res.json()
            if temp_data.get('stat') == "OK":
                data = temp_data
                break
        except:
            pass
        
        target_date -= timedelta(days=1)
        attempts += 1

    if not data:
        st.error("ç„¡æ³•å¾è­‰äº¤æ‰€ç²å–æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– API ç‹€æ…‹ã€‚")
        return pd.DataFrame()

    # åˆ¤æ–·è³‡æ–™æ¬„ä½ (data9 æˆ– data8)
    target_key = 'data9' if 'data9' in data else 'data8'
    fields_key = 'fields9' if 'fields9' in data else 'fields8'
    
    df = pd.DataFrame(data[target_key], columns=data[fields_key])
    df['æˆäº¤é‡‘é¡'] = df['æˆäº¤é‡‘é¡'].str.replace(',', '').astype(float)
    df['è­‰åˆ¸ä»£è™Ÿ'] = df['è­‰åˆ¸ä»£è™Ÿ'] + ".TW"
    
    st.info(f"ğŸ“… æ•¸æ“šä¾†æºæ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
    return df.nlargest(100, 'æˆäº¤é‡‘é¡')[['è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', 'æ”¶ç›¤åƒ¹']]

def get_stock_data(symbol, period="1y"):
    try:
        df = yf.download(symbol, period=period, interval="1d", progress=False)
        if df.empty: return None
        df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        return df.reset_index()
    except:
        return None

# ==================== 2. é›²ç«¯åŒæ­¥æ¨¡çµ„ ====================

def get_gspread_client():
    if not os.path.exists(CREDENTIALS_JSON):
        st.warning(f"âš ï¸ æ‰¾ä¸åˆ° {CREDENTIALS_JSON}ã€‚")
        return None
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_JSON, scope)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"âŒ Google é€£æ¥å¤±æ•—: {e}")
        return None

def save_to_sheets(new_data):
    client = get_gspread_client()
    if client:
        try:
            sh = client.open(SHEET_NAME)
            ws = sh.sheet1
            if ws.row_count <= 1 and (not ws.cell(1, 1).value):
                ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
            ws.append_rows(new_data)
            return True
        except Exception as e:
            st.error(f"âŒ å¯«å…¥é›²ç«¯å¤±æ•—: {e}")
    return False

# ==================== 3. é è¨“ç·´æ¨è«–æ¨¡çµ„ ====================

@st.cache_resource
def get_trained_base_model():
    """å»ºç«‹åŸºæº–æ¨¡å‹ï¼ˆä»¥ 2330 ç‚ºè¨“ç·´æ¨£æ¿ï¼‰"""
    df = get_stock_data("2330.TW")
    if df is None: return None
    
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    
    X, y = [], []
    for i in range(60, len(scaled)):
        X.append(scaled[i-60:i, 0])
        y.append(scaled[i, 0])
    
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(60, 1)),
        tf.keras.layers.LSTM(50),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(np.array(X), np.array(y), epochs=3, batch_size=32, verbose=0)
    return model

def fast_predict(model, df):
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    last_60 = scaled[-60:].reshape(1, 60, 1)
    pred = model.predict(last_60, verbose=0)
    return scaler.inverse_transform(pred)[0][0]

# ==================== 4. ä¸»ä»‹é¢é‚è¼¯ ====================

def main():
    st.title("ğŸ“ˆ AI å°è‚¡ç™¾å¤§è¶¨å‹¢è‡ªå‹•åŒ–ç³»çµ±")
    
    tab1, tab2 = st.tabs(["ğŸš€ å•Ÿå‹•ç™¾å¤§åˆ†æ", "ğŸ§ é æ¸¬å°éŒ¯åæ€"])

    with tab1:
        st.markdown("### è‡ªå‹•ç¯©é¸å°è‚¡æˆäº¤å€¼ Top 100 ä¸¦å­˜å…¥é›²ç«¯")
        if st.button("åŸ·è¡Œæ‰¹æ¬¡é æ¸¬"):
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–..."):
                top_100 = get_top_100_value_stocks()
                model = get_trained_base_model()
            
            if not top_100.empty and model:
                results = []
                bar = st.progress(0)
                msg = st.empty()
                
                for i, row in top_100.iterrows():
                    symbol = row['è­‰åˆ¸ä»£è™Ÿ']
                    msg.text(f"åˆ†æä¸­ ({i+1}/100): {symbol}")
                    
                    time.sleep(BATCH_CD)
                    df = get_stock_data(symbol)
                    
                    if df is not None and len(df) >= 60:
                        curr_p = df['Close'].iloc[-1]
                        pred_p = fast_predict(model, df)
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'),
                            symbol,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%",
                            "-", "-"
                        ])
                    bar.progress((i+1)/100)
                
                if save_to_sheets(results):
                    st.success("âœ… åˆ†æå®Œæˆï¼çµæœå·²åŒæ­¥è‡³ Google Sheetsã€‚")
                    st.dataframe(pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬åƒ¹","æ¼²å¹…","å¯¦éš›","èª¤å·®"]))

    with tab2:
        st.subheader("æ­·å²é æ¸¬åæ€")
        client = get_gspread_client()
        if client:
            try:
                ws = client.open(SHEET_NAME).sheet1
                df_h = pd.DataFrame(ws.get_all_records())
                if not df_h.empty:
                    st.write("### æœ€è¿‘ 20 ç­†é æ¸¬ç´€éŒ„")
                    st.dataframe(df_h.tail(20))
                else:
                    st.info("å°šç„¡ç´€éŒ„ã€‚")
            except:
                st.error("è®€å–å¤±æ•—ã€‚")

if __name__ == "__main__":
    main()
