import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import gspread
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials
from datetime import datetime
import time
import os
import random
import urllib3

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="AI è‚¡å¸‚å…¨èƒ½å°ˆå®¶ v16.7", layout="wide")

# --- åƒæ•¸èˆ‡é‡‘é‘°è¨­å®š ---
SHEET_NAME = "Stock_Predictions_History"
CREDENTIALS_JSON = "eco-precept-485904-j5-7ef3cdda1b03.json"

# ä½¿ç”¨æ‚¨æä¾›çš„é è¨­ API KEY
DEFAULT_GEMINI_KEY = "AIzaSyDE4yDZMnniFaYLQd-LK7WSQpHh-6JRA3Q"
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", DEFAULT_GEMINI_KEY)

# åˆå§‹åŒ– Gemini AI
try:
    genai.configure(api_key=GEMINI_API_KEY)
    ai_model = genai.GenerativeModel('gemini-1.5-flash')
except Exception as e:
    st.error(f"Gemini åˆå§‹åŒ–å¤±æ•—: {e}")

# ==================== 1. é›²ç«¯é€£ç·šæ¨¡çµ„ (ä¿®æ­£æˆæ¬ŠéŒ¯èª¤) ====================

def get_gspread_client():
    """è™•ç†ç§é‘°æ ¼å¼ä¸¦å»ºç«‹ Google Sheets é€£ç·š"""
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    try:
        if "gcp_service_account" in st.secrets:
            creds_info = dict(st.secrets["gcp_service_account"])
            # å¼·åˆ¶è½‰ç¾©æ›è¡Œç¬¦è™Ÿé˜²æ­¢ Metadata å ±éŒ¯
            creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        elif os.path.exists(CREDENTIALS_JSON):
            creds = Credentials.from_service_account_file(CREDENTIALS_JSON, scopes=scopes)
        else:
            return None
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"âŒ Google Sheets æˆæ¬Šå¤±æ•—: {e}")
        return None

def get_top_100_tickers():
    """æ­¥é©Ÿ 1ï¼šå¾å…±ç”¨ EXCEL ç¬¬ä¸€é æŠ“å–å‰ 100 æ”¯è‚¡ç¥¨"""
    client = get_gspread_client()
    if not client: return []
    try:
        sh = client.open(SHEET_NAME)
        ws = sh.get_worksheet(0) # è®€å–ç¬¬ä¸€é 
        data = ws.get_all_records()
        df = pd.DataFrame(data)
        # æŠ“å–æ¨™é¡Œç‚º "è‚¡ç¥¨ä»£è™Ÿ" çš„ B æ¬„æ•¸æ“š
        return df['è‚¡ç¥¨ä»£è™Ÿ'].dropna().astype(str).head(100).tolist()
    except Exception as e:
        st.error(f"ç„¡æ³•è®€å–è‚¡ç¥¨æ¸…å–®: {e}")
        return []

# ==================== 2. å¤šç¶­åº¦åˆ†æèˆ‡çˆ¬èŸ²æ¨¡çµ„ ====================

def fetch_stock_news(symbol):
    """æ­¥é©Ÿ 2-äºŒï¼šçˆ¬èŸ²å››å¤§æ–°èç¶²æœå°‹ç›¸é—œæ–°è"""
    stock_id = symbol.split('.')[0]
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    # å®šç¾©çˆ¬å–ç›®æ¨™
    sources = [
        "https://www.ftnn.com.tw/category/6",           # FTNN
        "https://news.wearn.com/index.html",            # èšè²¡ç¶²
        "https://news.cnyes.com/news/cat/tw_stock_news",# é‰…äº¨ç¶²
        "https://money.udn.com/money/index"             # ç¶“æ¿Ÿæ—¥å ±
    ]
    news_text = ""
    # éš¨æ©ŸæŒ‘é¸ 1-2 å€‹ä¾†æºä»¥é˜²è¢«å°é– IP
    for url in random.sample(sources, 2):
        try:
            res = requests.get(url, headers=headers, timeout=5)
            soup = BeautifulSoup(res.text, 'html.parser')
            # æŠ“å–æ¨™é¡Œä¸­åŒ…å«è‚¡ç¥¨ä»£ç¢¼çš„æ–‡å­—
            titles = [t.get_text() for t in soup.find_all(['h3', 'a', 'h2']) if stock_id in t.get_text()]
            news_text += " ".join(titles[:3]) + " "
        except: continue
    return news_text if news_text else "æŸ¥ç„¡è¿‘æœŸç›¸é—œé‡å¤§æ–°è"

def calculate_technical_score(ticker, df):
    """æ­¥é©Ÿ 2-ä¸€ï¼šæŠ“å–åŸºæœ¬é¢ã€æŠ€è¡“é¢ä¸¦å¯¦ä½œç©åˆ†åˆ¶"""
    score = 0
    try:
        # æŠ€è¡“é¢ï¼šé»ƒé‡‘äº¤å‰åˆ¤å®š (MA5 ä¸Šç©¿ MA20)
        ma5 = df['Close'].rolling(5).mean().iloc[-1]
        ma20 = df['Close'].rolling(20).mean().iloc[-1]
        ma5_prev = df['Close'].rolling(5).mean().iloc[-2]
        ma20_prev = df['Close'].rolling(20).mean().iloc[-2]
        
        if ma5 > ma20 and ma5_prev <= ma20_prev:
            score += 5  # å¼·åŠ›é»ƒé‡‘äº¤å‰åŠ åˆ†
        elif ma5 > ma20:
            score += 2  # å¤šé ­æ’åˆ—åŠ åˆ†
            
        # åŸºæœ¬é¢ï¼šæœ¬ç›Šæ¯” (PE Ratio)
        info = yf.Ticker(ticker).info
        pe = info.get('forwardPE', 100)
        if pe < 15: score += 3 # ä½æœ¬ç›Šæ¯”åŠ åˆ†
        elif pe < 25: score += 1
    except: pass
    return score

# ==================== 3. ä¸»åŸ·è¡Œç¨‹åº (æŠ—å°é–èˆ‡é æ¸¬) ====================

st.title("ğŸ›¡ï¸ AI è‚¡å¸‚æ·±åº¦é æ¸¬ç³»çµ± v16.7")
st.markdown(f"**ä½¿ç”¨ Gemini API Key:** `{GEMINI_API_KEY[:8]}...`")

if st.button("ğŸš€ é–‹å§‹å…¨è‡ªå‹• Top 100 ç©åˆ†é æ¸¬åˆ†æ"):
    tickers = get_top_100_tickers()
    client = get_gspread_client()
    
    if client and tickers:
        sh = client.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        p_bar = st.progress(0)
        status_msg = st.empty()
        
        # æ­¥é©Ÿ 1ï¼šæ‰¹é‡ç²å–å…¨å¸‚å ´æ•¸æ“š
        status_msg.text("æ­£åœ¨åŒæ­¥æ‰¹é‡å¸‚å ´æ­·å²æ•¸æ“š...")
        all_hist = yf.download(tickers, period="3mo", group_by='ticker', threads=True, progress=False)
        
        for idx, t in enumerate(tickers):
            try:
                status_msg.text(f"åˆ†æä¸­ ({idx+1}/100): {t}")
                
                # ç²å–å€‹åˆ¥è‚¡ç¥¨æ•¸æ“š
                df = all_hist[t].dropna() if isinstance(all_hist.columns, pd.MultiIndex) else all_hist.dropna()
                if df.empty: continue
                
                # åŸ·è¡Œåˆ†æèˆ‡çˆ¬èŸ²
                curr_price = round(float(df['Close'].iloc[-1]), 2)
                tech_score = calculate_technical_score(t, df)
                news_content = fetch_stock_news(t)
                
                # æ­¥é©Ÿ 2-äºŒï¼šä¸Ÿçµ¦ Gemini åˆ†æç©åˆ†èˆ‡é æ¸¬èµ°å‹¢
                prompt = f"""
                åˆ†æè‚¡ç¥¨ {t}ã€‚ç¾åƒ¹ {curr_price}ã€‚æŠ€è¡“åŸºæœ¬åˆ† {tech_score}ã€‚æ–°èå…§å®¹ï¼š{news_content}ã€‚
                è«‹æ ¹æ“šé€™äº›è³‡è¨Šçµ¦å‡ºæœªä¾† 5 å€‹äº¤æ˜“æ—¥çš„é æœŸæ”¶ç›¤åƒ¹ã€‚
                è«‹åš´æ ¼éµå®ˆæ ¼å¼å›ç­” 5 å€‹æ•¸å­—ï¼Œä»¥é€—è™Ÿåˆ†éš”ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
                æ•¸å­—1,æ•¸å­—2,æ•¸å­—3,æ•¸å­—4,æ•¸å­—5
                """
                response = ai_model.generate_content(prompt)
                # è§£æé æ¸¬åƒ¹æ ¼
                preds = [float(p.strip()) for p in response.text.strip().split(',')]
                
                # æ­¥é©Ÿ 3ï¼šå¯«å…¥ E-J æ¬„ä½
                # E-I æ¬„: 5æ—¥é æ¸¬åƒ¹æ ¼, J æ¬„: èª¤å·®% (è¨­ç‚ºå¾…å®š)
                ws.update(f"E{idx+2}:J{idx+2}", [preds + ["-"]])
                
                # æ™ºèƒ½å†·å»æ©Ÿåˆ¶é˜²æ­¢ Too Many Requests
                time.sleep(random.uniform(1.0, 2.0))
                if (idx + 1) % 10 == 0:
                    status_msg.text("åŸ·è¡Œåˆ†æ®µå†·å»ä¸­ (15ç§’)...")
                    time.sleep(15)
                    
            except Exception as e:
                st.warning(f"è·³é {t}: {e}")
                
            p_bar.progress((idx + 1) / len(tickers))
            
        status_msg.text("âœ… å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢")
        st.success("ğŸ‰ Top 100 æ¨™çš„åŸºæœ¬é¢ã€æŠ€è¡“é¢ã€æ–°èåˆ†æèˆ‡ 5 æ—¥é æ¸¬å·²åŒæ­¥è‡³é›²ç«¯ï¼")
