import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import gspread
import requests
from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials
from datetime import datetime
import time
import os
import random
import urllib3

# --- åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="å°è‚¡é‡åŒ–é æ¸¬ç³»çµ± v19.0", layout="wide")

# --- åƒæ•¸è¨­å®š ---
SHEET_NAME = "Stock_Predictions_History"
CREDENTIALS_JSON = "eco-precept-485904-j5-7ef3cdda1b03.json"

# ==================== 1. é›²ç«¯é€£ç·šæ¨¡çµ„ (æ’é™¤ AI) ====================

def get_gspread_client():
    """å»ºç«‹ Google Sheets é€£ç·šï¼Œä¿®æ­£æˆæ¬Š Header å ±éŒ¯"""
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    try:
        if "gcp_service_account" in st.secrets:
            creds_info = dict(st.secrets["gcp_service_account"])
            # å¼·åˆ¶éæ¿¾ç§é‘°å­—å…ƒ
            creds_info["private_key"] = creds_info["private_key"].replace("\\n", "\n")
            creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        elif os.path.exists(CREDENTIALS_JSON):
            creds = Credentials.from_service_account_file(CREDENTIALS_JSON, scopes=scopes)
        else:
            return None
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"âŒ Google Sheets æˆæ¬Šå¤±æ•—: {e}")
        return None

def get_target_tickers():
    """æ­¥é©Ÿ 1ï¼šæŠ“å– Excel ç¬¬ä¸€é çš„ Top 100 è‚¡ç¥¨ä»£è™Ÿ"""
    client = get_gspread_client()
    if not client: return []
    try:
        sh = client.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        df = pd.DataFrame(ws.get_all_records())
        return df['è‚¡ç¥¨ä»£è™Ÿ'].dropna().astype(str).head(100).tolist()
    except Exception as e:
        st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
        return []

# ==================== 2. åˆ†ææ ¸å¿ƒï¼šç´”é‡åŒ–èˆ‡çˆ¬èŸ²æ¨¡çµ„ ====================

def get_stock_news_summary(symbol):
    """æ­¥é©Ÿ 2-äºŒï¼šæœå°‹å››å¤§æ–°èç¶²æ¨™çš„è³‡è¨Š (ç´”æŠ“å–ä¾›åƒè€ƒ)"""
    stock_id = symbol.split('.')[0]
    headers = {'User-Agent': 'Mozilla/5.0'}
    # é‡é»æŠ“å–é‰…äº¨ç¶²èˆ‡ç¶“æ¿Ÿæ—¥å ±
    url = "https://news.cnyes.com/news/cat/tw_stock_news"
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        relevant = [t.get_text() for t in soup.find_all(['h3', 'a']) if stock_id in t.get_text()]
        return len(relevant) # å›å‚³æ–°èç†±åº¦(æ•¸é‡)
    except:
        return 0

def calculate_score_prediction(ticker, df, news_count):
    """
    æ­¥é©Ÿ 2-ä¸€/ä¸‰ï¼šç©åˆ†åˆ¶é æ¸¬ç®—æ³• (æ›¿ä»£ Gemini)
    åŒ…å«ï¼šé»ƒé‡‘äº¤å‰ + åŸºæœ¬é¢ + æ–°èç†±åº¦
    """
    score = 0
    try:
        # 1. æŠ€è¡“é¢ï¼šå‡ç·šé»ƒé‡‘äº¤å‰ (MA5 > MA20)
        ma5 = df['Close'].rolling(5).mean().iloc[-1]
        ma20 = df['Close'].rolling(20).mean().iloc[-1]
        if ma5 > ma20: score += 5
        
        # 2. åŸºæœ¬é¢ï¼šä½æœ¬ç›Šæ¯”åˆ¤å®š
        info = yf.Ticker(ticker).info
        pe = info.get('forwardPE', 100)
        if pe < 15: score += 3
        
        # 3. æ–°èç†±åº¦åŠ åˆ†
        if news_count > 0: score += 2
        
        # --- é æ¸¬é‚è¼¯ï¼šæ ¹æ“šç©åˆ†æ¬Šé‡èˆ‡æ­·å²æ³¢å‹•ç‡è¨ˆç®— ---
        volatility = df['Close'].pct_change().std() # æ­·å²æ³¢å‹•ç‡
        last_price = float(df['Close'].iloc[-1])
        
        # è¶¨å‹¢å› å­ï¼šç©åˆ†è¶Šé«˜ï¼Œæ¯æ—¥é æœŸæ¼²å¹…è¶Šæ­£å‘
        trend = (score - 5) * 0.001 # åŸºæº–åˆ†ç‚º5åˆ†
        
        preds = []
        temp_p = last_price
        for i in range(1, 6):
            # éš¨æ©Ÿæ“¾å‹• (éš¨æ©Ÿæ€§ç¢ºä¿é æ¸¬ä¸ç‚ºç›´ç·š)
            move = trend + np.random.normal(0, volatility * 0.5)
            temp_p *= (1 + move)
            preds.append(round(temp_p, 2))
        return preds
    except:
        return [round(float(df['Close'].iloc[-1]) * 1.01, 2)] * 5

# ==================== 3. ä¸»åŸ·è¡Œæµç¨‹ ====================

st.title("ğŸ“Š å°è‚¡é‡åŒ–å› å­åˆ†æç³»çµ± (ç§»é™¤ AI ç‰ˆ)")
st.info("æ¨¡å¼ï¼šé€éåŸºæœ¬é¢ã€æŠ€è¡“é¢(é»ƒé‡‘äº¤å‰)èˆ‡æ–°èç†±åº¦é€²è¡Œç©åˆ†åˆ¶åƒ¹æ ¼é æ¸¬ã€‚")

if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå…¨å¸‚å ´å‰ 100 åé‡åŒ–é æ¸¬"):
    tickers = get_target_tickers()
    client = get_gspread_client()
    
    if client and tickers:
        sh = client.open(SHEET_NAME)
        ws = sh.get_worksheet(0)
        p_bar = st.progress(0)
        status = st.empty()
        
        # æ‰¹é‡ä¸‹è¼‰æ•¸æ“šé¿å…é™æµ
        status.text("æ‰¹é‡ç²å–å¸‚å ´æ•¸æ“šä¸­...")
        all_hist = yf.download(tickers, period="3mo", group_by='ticker', threads=True, progress=False)
        
        for idx, t in enumerate(tickers):
            try:
                status.text(f"è¨ˆç®—å› å­ä¸­ ({idx+1}/100): {t}")
                df = all_hist[t].dropna() if isinstance(all_hist.columns, pd.MultiIndex) else all_hist.dropna()
                if df.empty: continue
                
                # åŸ·è¡Œåˆ†ææ­¥é©Ÿ
                news_hot = get_stock_news_summary(t)
                # å–å¾— 5 æ—¥é æ¸¬åƒ¹æ ¼
                preds = calculate_score_prediction(t, df, news_hot)
                
                # å¯«å…¥ Excel E-J æ¬„ä½
                # E-I: é æ¸¬åƒ¹, J: èª¤å·®% (é è¨­ "-")
                final_row = preds + ["-"]
                ws.update(f"E{idx+2}:J{idx+2}", [final_row])
                
                # æ™ºèƒ½å†·å»æ©Ÿåˆ¶
                time.sleep(random.uniform(1.0, 2.0))
                if (idx + 1) % 15 == 0:
                    time.sleep(10)
                    
            except Exception as e:
                st.warning(f"è·³é {t}: {e}")
                
            p_bar.progress((idx + 1) / len(tickers))
            
        status.text("âœ… ä»»å‹™å·²å®Œæˆ")
        st.success("ğŸ‰ é‡åŒ–åˆ†ææ•¸æ“šå·²æˆåŠŸæ›´æ–°è‡³ Excel E-J æ¬„ä½ï¼")
