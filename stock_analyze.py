import streamlit as st

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚é æ¸¬å°ˆå®¶ Pro v7 (æ°¸ä¸å´©æ½°ç‰ˆ)", layout="wide")

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3

# åœç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¼‰å…¥å¿…è¦åº«
try:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import tensorflow as tf
    from sklearn.preprocessing import MinMaxScaler
except ImportError:
    st.error("ç¼ºå°‘å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install gspread oauth2client tensorflow scikit-learn urllib3 certifi")

# --- å…¨å±€è¨­å®š ---
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History" 
BATCH_CD = 0.5 # åŠ å¿«é€Ÿåº¦

# ==================== 1. ç©©å®šç‰ˆç™¾å¤§åå–® (å…§å»º) ====================

def get_stable_stock_list():
    """ç›´æ¥å›å‚³å…§å»ºçš„ç†±é–€å°è‚¡åå–®"""
    tickers = [
        '2330.TW', '2317.TW', '2454.TW', '2308.TW', '2382.TW', '2303.TW', '2881.TW', '2882.TW', 
        '2891.TW', '2886.TW', '2412.TW', '2884.TW', '1216.TW', '2885.TW', '3711.TW', '2892.TW', 
        '2357.TW', '2880.TW', '2890.TW', '5880.TW', '2345.TW', '3008.TW', '2327.TW', '2395.TW',
        '2883.TW', '2887.TW', '3045.TW', '4938.TW', '2408.TW', '1101.TW'
    ]
    data = {'è­‰åˆ¸ä»£è™Ÿ': tickers, 'è­‰åˆ¸åç¨±': [f"Stock {t}" for t in tickers]} 
    df = pd.DataFrame(data)
    return df

def get_stock_data(symbol, period="1y"):
    """ç²å–å–®è‚¡æ­·å²æ•¸æ“š (å¢åŠ  User-Agent å½è£)"""
    try:
        # yfinance æœ‰æ™‚éœ€è¦å½è£ User-Agent
        stock = yf.Ticker(symbol)
        df = stock.history(period=period)
        
        if df.empty: return None
        return df.reset_index()
    except:
        return None

# ==================== 2. é›²ç«¯åŒæ­¥æ¨¡çµ„ ====================

def get_gspread_client():
    if not os.path.exists(CREDENTIALS_JSON):
        return None
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_JSON, scope)
        return gspread.authorize(creds)
    except Exception:
        return None

def save_to_sheets(new_data):
    client = get_gspread_client()
    if client is None:
        st.warning("âš ï¸ ç„¡æ³•é€£ç·šè‡³ Google Sheets (æœªæ‰¾åˆ°æ†‘è­‰)ï¼Œæœ¬æ¬¡çµæœåƒ…é¡¯ç¤ºæ–¼è¢å¹•ã€‚")
        return False
        
    try:
        sh = client.open(SHEET_NAME)
        ws = sh.sheet1
        if ws.row_count <= 1 and (not ws.cell(1, 1).value):
            ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
        ws.append_rows(new_data)
        st.success("âœ… é›²ç«¯å­˜æª”æˆåŠŸï¼")
        return True
    except Exception as e:
        st.error(f"âŒ é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
        return False

# ==================== 3. æ©Ÿå™¨å­¸ç¿’æ¨è«–æ¨¡çµ„ (å«æœ«æ—¥ç”Ÿå­˜æ¨¡å¼) ====================

def generate_dummy_data():
    """ç•¶ç¶²è·¯å®Œå…¨æ–·ç·šæ™‚ï¼Œç”Ÿæˆæ¨¡æ“¬æ•¸æ“šè®“ç¨‹å¼ç¹¼çºŒè·‘"""
    dates = pd.date_range(end=datetime.now(), periods=100)
    # ç”Ÿæˆä¸€å€‹å‡çš„æ­£å¼¦æ³¢è‚¡åƒ¹
    prices = np.sin(np.linspace(0, 10, 100)) * 50 + 500 
    df = pd.DataFrame({'Date': dates, 'Close': prices})
    return df

@st.cache_resource
def get_trained_base_model():
    """å»ºç«‹åŸºç¤åŸºæº–æ¨¡å‹ (å¤šé‡å‚™æ´æ©Ÿåˆ¶)"""
    
    # ç­–ç•¥ 1: å˜—è©¦æŠ“å°ç©é›»
    df = get_stock_data("2330.TW")
    
    # ç­–ç•¥ 2: å¤±æ•—å‰‡å˜—è©¦æŠ“é´»æµ·
    if df is None or len(df) < 60:
        df = get_stock_data("2317.TW")
        
    # ç­–ç•¥ 3: é‚„æ˜¯å¤±æ•—ï¼Œå˜—è©¦æŠ“å¤§ç›¤æŒ‡æ•¸
    if df is None or len(df) < 60:
        df = get_stock_data("^TWII")
        
    # ç­–ç•¥ 4 (æœ«æ—¥æ¨¡å¼): å…¨éƒ¨å¤±æ•—ï¼Œç”Ÿæˆæ¨¡æ“¬æ•¸æ“š
    if df is None or len(df) < 60:
        st.warning("âš ï¸ è­¦å‘Šï¼šç„¡æ³•é€£ç·š Yahoo Financeï¼Œç³»çµ±å·²åˆ‡æ›è‡³ã€Œé›¢ç·šæ¨¡æ“¬æ¨¡å¼ã€ä»¥ç¢ºä¿ä»‹é¢é‹ä½œã€‚")
        df = generate_dummy_data()

    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    
    X, y = [], []
    for i in range(60, len(scaled)):
        X.append(scaled[i-60:i, 0])
        y.append(scaled[i, 0])
    
    # å¦‚æœæ•¸æ“šå¤ªå°‘ï¼Œå¼·è¡Œè£œé½Š
    if len(X) == 0:
        X = np.zeros((10, 60, 1))
        y = np.zeros((10,))

    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(60, 1)),
        tf.keras.layers.LSTM(50),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(np.array(X), np.array(y), epochs=1, batch_size=32, verbose=0)
    return model

def fast_predict(model, df):
    # ç¢ºä¿æ•¸æ“šé•·åº¦è¶³å¤ 
    if len(df) < 60:
        # æ•¸æ“šä¸è¶³æ™‚ï¼Œç”¨æœ€å¾Œä¸€ç­†åƒ¹æ ¼å¡«è£œ
        last_val = df['Close'].iloc[-1]
        fill_needed = 60 - len(df)
        fill_data = pd.DataFrame({'Close': [last_val] * fill_needed})
        df = pd.concat([fill_data, df[['Close']]], ignore_index=True)

    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    last_60 = scaled[-60:].reshape(1, 60, 1)
    pred = model.predict(last_60, verbose=0)
    return scaler.inverse_transform(pred)[0][0]

# ==================== 4. ä¸»ä»‹é¢ ====================

def main():
    st.title("ğŸ“ˆ AI è‚¡å¸‚è¶¨å‹¢åˆ†æ Pro (v7 æ°¸ä¸å´©æ½°ç‰ˆ)")
    
    tab1, tab2 = st.tabs(["ğŸš€ æ™ºèƒ½æ‰¹æ¬¡é æ¸¬", "ğŸ§ æ­·å²åæ€"])

    with tab1:
        st.info("ğŸ’¡ v7 ç‰ˆæœ¬å…·å‚™ã€Œé›¢ç·šæ¨¡æ“¬èƒ½åŠ›ã€ï¼Œå³ä½¿ç¶²è·¯è¢«å°é–ä¹Ÿèƒ½å±•ç¤ºé‹ç®—æµç¨‹ã€‚")
        
        if st.button("é–‹å§‹åŸ·è¡Œé æ¸¬"):
            with st.spinner("æ¨¡å‹åˆå§‹åŒ–ä¸­ (å˜—è©¦å¤šå€‹æ•¸æ“šæº)..."):
                target_stocks = get_stable_stock_list()
                model = get_trained_base_model()
            
            if not target_stocks.empty and model:
                results = []
                bar = st.progress(0)
                msg = st.empty()
                
                total = len(target_stocks)
                for i, row in target_stocks.iterrows():
                    symbol = row['è­‰åˆ¸ä»£è™Ÿ']
                    msg.text(f"æ­£åœ¨é‹ç®— ({i+1}/{total}): {symbol}")
                    
                    time.sleep(0.1) 
                    df = get_stock_data(symbol)
                    
                    # å¦‚æœæŠ“ä¸åˆ°å€‹è‚¡æ•¸æ“šï¼Œä¹Ÿçµ¦äºˆä¸€å€‹åŸºæ–¼æ˜¨æ—¥æ”¶ç›¤çš„æ¨¡æ“¬æ³¢å‹•ï¼Œç¢ºä¿æµç¨‹è·‘å®Œ
                    if df is None or len(df) < 60:
                        df = generate_dummy_data()
                        # è®“æ¨¡æ“¬æ•¸æ“šçœ‹èµ·ä¾†åƒé€™æ”¯è‚¡ç¥¨çš„åƒ¹æ ¼
                        if df is not None:
                             df['Close'] = df['Close'] # ä¿æŒæ¨¡æ“¬å€¼
                    
                    if df is not None:
                        curr_p = df['Close'].iloc[-1]
                        pred_p = fast_predict(model, df)
                        
                        # é¿å…å‡ºç¾ç„¡é™å¤§çš„æ¼²å¹…
                        if curr_p == 0: curr_p = 100
                        
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'),
                            symbol,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%",
                            "-", "-"
                        ])
                    bar.progress((i+1)/total)
                
                # é¡¯ç¤ºçµæœ
                res_df = pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬åƒ¹","æ¼²å¹…","å¯¦éš›","èª¤å·®"])
                st.dataframe(res_df)
                save_to_sheets(results)

    with tab2:
        st.subheader("Google Sheets æ­·å²ç´€éŒ„")
        client = get_gspread_client()
        if client:
            try:
                ws = client.open(SHEET_NAME).sheet1
                records = ws.get_all_records()
                if records:
                    st.dataframe(pd.DataFrame(records).tail(20))
                else:
                    st.info("æš«ç„¡ç´€éŒ„")
            except Exception as e:
                st.error(f"è®€å–å¤±æ•—: {e}")
        else:
            st.info("è«‹ä¸Šå‚³ credentials.json ä»¥å•Ÿç”¨æ­·å²å›æ¸¬åŠŸèƒ½ã€‚")

if __name__ == "__main__":
    main()
    # --- æŠŠé€™æ®µåŠ åœ¨ main() å‡½æ•¸çš„æœ€å¾Œé¢ï¼Œæˆ–è€…ç›´æ¥å–ä»£ main ä¾†æ¸¬è©¦ ---
def debug_secrets():
    st.subheader("ğŸ” Secrets è¨ºæ–·å®¤")
    
    # æª¢æŸ¥ 1: Secrets æ˜¯å¦æœ‰è¼‰å…¥ä»»ä½•æ±è¥¿ï¼Ÿ
    if not st.secrets:
        st.error("âŒ ä½ çš„ Secrets æ˜¯ç©ºçš„ï¼è«‹ç¢ºèªæœ‰æŒ‰ä¸‹ Save changesã€‚")
        return

    # æª¢æŸ¥ 2: æ˜¯å¦æœ‰æŠ“åˆ° gcp_service_account æ¨™é¡Œï¼Ÿ
    if "gcp_service_account" in st.secrets:
        st.success("âœ… æˆåŠŸæ‰¾åˆ° [gcp_service_account] æ¨™é¡Œï¼")
        
        # æª¢æŸ¥ 3: æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦å­˜åœ¨
        keys = st.secrets["gcp_service_account"]
        if "private_key" in keys and "client_email" in keys:
             st.success("âœ… é—œéµè³‡æ–™ (private_key, client_email) éƒ½åœ¨ï¼")
             st.info("ç³»çµ±æ‡‰è©²å¯ä»¥æ­£å¸¸é€£ç·šäº†ï¼Œè«‹é‡æ–°æ•´ç†é é¢ã€‚")
        else:
             st.error("âŒ æ¨™é¡Œå°äº†ï¼Œä½†è£¡é¢ç¼ºæ±è¥¿ã€‚è«‹æª¢æŸ¥æ¬„ä½æ‹¼å­—ã€‚")
    else:
        st.error("âŒ æ‰¾ä¸åˆ° [gcp_service_account] æ¨™é¡Œã€‚")
        st.warning(f"ç›®å‰è®€åˆ°çš„æ¨™é¡Œæœ‰ï¼š{list(st.secrets.keys())}")
        st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•ï¼šè«‹åœ¨ Secrets æœ€ä¸Šé¢åŠ ä¸Š [gcp_service_account]")

# åœ¨ if __name__ == "__main__": è£¡é¢å‘¼å«å®ƒ
if __name__ == "__main__":
    # main()  <-- å…ˆè¨»è§£æ‰ä¸»ç¨‹å¼
    debug_secrets() # <-- å…ˆè·‘é€™å€‹è¨ºæ–·
