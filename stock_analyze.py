import streamlit as st
import importlib.metadata

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚å…¨èƒ½å°ˆå®¶ v14 (æœ¬åœ°é‹ç®—æ’è¡Œç‰ˆ)", layout="wide", initial_sidebar_state="expanded")

# --- æª¢æ¸¬å¥—ä»¶ ---
try:
    gspread_version = importlib.metadata.version("gspread")
    auth_version = importlib.metadata.version("google-auth")
except:
    pass

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3
import random

# åœç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- è¼‰å…¥é›²ç«¯èˆ‡ AI åº« ---
try:
    import gspread
    from google.oauth2.service_account import Credentials
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Input
    from sklearn.preprocessing import MinMaxScaler
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    st.error("ç¼ºå°‘ AI å¥—ä»¶ï¼Œè«‹æª¢æŸ¥ requirements.txt")

import warnings
warnings.filterwarnings('ignore')

# --- å…¨å±€è¨­å®š ---
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History"

# ==================== 0. é›²ç«¯é€£ç·šæ¨¡çµ„ (æ”¯æ´å¤šé‡åˆ†é ) ====================

def get_gspread_client():
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    
    if "gcp_service_account" in st.secrets:
        try:
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
            return gspread.authorize(creds)
        except Exception:
            return None
    elif os.path.exists(CREDENTIALS_JSON):
        try:
            creds = Credentials.from_service_account_file(CREDENTIALS_JSON, scopes=scopes)
            return gspread.authorize(creds)
        except Exception:
            return None
    return None

def save_to_sheets(new_data, sheet_index=0):
    """
    sheet_index=0: å­˜å…¥ç¬¬ä¸€åˆ†é  (å–®è‚¡åˆ†æ)
    sheet_index=1: å­˜å…¥ç¬¬äºŒåˆ†é  (å…¨å¸‚å ´æƒæ)
    """
    client = get_gspread_client()
    if client is None:
        st.warning("âš ï¸ ç„¡æ³•é€£ç·šè‡³ Google Sheetsï¼Œè«‹æª¢æŸ¥ Secretsã€‚")
        return False
    try:
        sh = client.open(SHEET_NAME)
        
        # --- åˆ†é è™•ç†é‚è¼¯ ---
        target_ws = None
        try:
            # å˜—è©¦ç²å–æŒ‡å®šç´¢å¼•çš„åˆ†é 
            # get_worksheet(0) æ˜¯ç¬¬ä¸€é , get_worksheet(1) æ˜¯ç¬¬äºŒé 
            all_ws = sh.worksheets()
            if len(all_ws) > sheet_index:
                target_ws = all_ws[sheet_index]
            else:
                # å¦‚æœåˆ†é ä¸å¤ ï¼Œå°±å»ºç«‹æ–°çš„
                target_ws = sh.add_worksheet(title=f"Scan_Result_{len(all_ws)+1}", rows=500, cols=10)
        except Exception as e:
            st.warning(f"åˆ†é å­˜å–ç•°å¸¸ï¼Œå˜—è©¦å»ºç«‹æ–°åˆ†é : {e}")
            target_ws = sh.add_worksheet(title=f"Backup_{datetime.now().strftime('%H%M')}", rows=500, cols=10)

        # å¯«å…¥æ¨™é¡Œ (å¦‚æœè¡¨æ˜¯ç©ºçš„)
        if target_ws.row_count > 0:
            try:
                val = target_ws.acell('A1').value
                if not val:
                    target_ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
            except:
                pass
        else:
             target_ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
             
        target_ws.append_rows(new_data)
        return True
    except Exception as e:
        st.error(f"âŒ é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
        return False

# ==================== 1. æœ¬åœ°é‹ç®—å¸‚å ´æƒæå¼•æ“ (å–ä»£ Yahoo çˆ¬èŸ²) ====================

def get_market_universe():
    """
    å…§å»º 400+ æª”å°è‚¡æ´»èºåå–®ï¼Œæ¶µè“‹æ¬Šå€¼ã€AIã€èˆªé‹ã€é‡‘èã€é‡é›»ã€ç”ŸæŠ€ç­‰æ¿å¡Šã€‚
    é€™èƒ½ç¢ºä¿åœ¨ Yahoo/è­‰äº¤æ‰€å°é– IP æ™‚ï¼Œç¨‹å¼ä¾ç„¶èƒ½é‹ä½œã€‚
    """
    tickers = [
        # åŠå°é«”/æ¬Šå€¼
        '2330.TW', '2317.TW', '2454.TW', '2308.TW', '2303.TW', '2382.TW', '2379.TW', '3661.TW', '3443.TW', '3035.TW',
        '2301.TW', '2345.TW', '2408.TW', '2449.TW', '3037.TW', '3034.TW', '3711.TW', '2357.TW', '3231.TW', '2356.TW',
        '6669.TW', '2376.TW', '2368.TW', '3017.TW', '3533.TW', '5269.TW', '5274.TW', '6271.TW', '6531.TW', '8069.TW',
        '3189.TW', '3008.TW', '3406.TW', '3653.TW', '4961.TW', '4966.TW', '6176.TW', '6415.TW', '6456.TW', '6515.TW',
        # AI ä¼ºæœå™¨/æ•£ç†±/æ©Ÿæ®¼
        '3324.TW', '2421.TW', '3013.TW', '3044.TW', '5483.TW', '6121.TW', '6213.TW', '8150.TW', '8996.TW', '2383.TW',
        '2388.TW', '3515.TW', '3694.TW', '8210.TW', '2486.TW', '6278.TW', '2059.TW', '3042.TW', '6117.TW', '8473.TW',
        # èˆªé‹
        '2603.TW', '2609.TW', '2615.TW', '2618.TW', '2610.TW', '2606.TW', '2605.TW', '2637.TW', '2633.TW', '2634.TW',
        # é‡é›»/ç¶ èƒ½
        '1513.TW', '1519.TW', '1503.TW', '1504.TW', '1514.TW', '1605.TW', '1609.TW', '1618.TW', '6806.TW', '3708.TW',
        '9958.TW', '3209.TW', '6282.TW', '6443.TW', '6477.TW', '8046.TW', '8938.TW', '9937.TW', '2049.TW',
        # é‡‘è
        '2881.TW', '2882.TW', '2891.TW', '2886.TW', '2884.TW', '2885.TW', '2880.TW', '2890.TW', '2892.TW', '2883.TW',
        '2887.TW', '2888.TW', '2801.TW', '2812.TW', '2834.TW', '2838.TW', '2845.TW', '2849.TW', '2850.TW', '2851.TW',
        # é¢æ¿/å…‰é›»/ç¶²é€š
        '2409.TW', '3481.TW', '6116.TW', '2344.TW', '3049.TW', '4904.TW', '4906.TW', '4938.TW', '5388.TW', '6285.TW',
        '2314.TW', '2324.TW', '2332.TW', '2340.TW', '2374.TW', '2392.TW', '2419.TW', '2439.TW', '2451.TW', '2481.TW',
        # å‚³ç”¢/åŸç‰©æ–™
        '2002.TW', '2014.TW', '2027.TW', '1101.TW', '1102.TW', '1301.TW', '1303.TW', '1326.TW', '6505.TW', '1402.TW',
        '1476.TW', '9904.TW', '9910.TW', '1717.TW', '1722.TW', '1907.TW', '2105.TW', '2501.TW', '2542.TW', '9945.TW'
    ]
    # å»é‡
    return list(set(tickers))

def scan_top_100_by_value_local():
    """
    æ ¸å¿ƒé‚è¼¯ï¼š
    1. è¼‰å…¥ 400+ æª”è‚¡ç¥¨
    2. æŠ“å–æœ€æ–°è‚¡åƒ¹èˆ‡æˆäº¤é‡
    3. è¨ˆç®—æˆäº¤å€¼ (Turnover) = Price * Volume
    4. æ’åºä¸¦å›å‚³ Top 100
    é€™å®Œç¾æ¨¡æ“¬äº† Yahoo çš„æ’è¡Œæ¦œï¼Œä½†é€Ÿåº¦æ›´å¿«ä¸”ç©©å®šã€‚
    """
    tickers = get_market_universe()
    st.info(f"ğŸ” è¼‰å…¥å…¨å¸‚å ´è§€å¯Ÿåå–® (å…± {len(tickers)} æª”)ï¼Œé–‹å§‹è¨ˆç®—æˆäº¤é‡å¿ƒ...")
    
    # åˆ†æ‰¹ä¸‹è¼‰ä»¥é˜²è¶…æ™‚
    batch_size = 50
    results = []
    
    progress = st.progress(0)
    status = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status.text(f"æ­£åœ¨æƒæå¸‚å ´æ•¸æ“šï¼šç¬¬ {i} ~ {i+len(batch)} æª”...")
        
        try:
            # åªæŠ“ 2 å¤©æ•¸æ“šå°±å¤ ç®—æˆäº¤å€¼äº†
            data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
            
            for t in batch:
                try:
                    # è™•ç† MultiIndex
                    if isinstance(data.columns, pd.MultiIndex):
                        if t in data.columns.levels[0]:
                            t_df = data[t].dropna()
                        else:
                            continue
                    else:
                        t_df = data.dropna()
                    
                    if not t_df.empty:
                        last_row = t_df.iloc[-1]
                        price = float(last_row['Close'])
                        volume = float(last_row['Volume'])
                        
                        # è¨ˆç®—æˆäº¤å€¼ (å„„å…ƒ)
                        turnover = (price * volume) / 1e8
                        
                        results.append({
                            "ticker": t,
                            "price": price,
                            "turnover": turnover
                        })
                except:
                    continue
        except:
            pass
        
        progress.progress(min((i + batch_size) / len(tickers), 1.0))
        time.sleep(0.5) # ç¦®è²Œæ€§å»¶é²
        
    status.empty()
    progress.empty()
    
    # æ’åºï¼šæˆäº¤å€¼ç”±å¤§åˆ°å°
    df_res = pd.DataFrame(results)
    if not df_res.empty:
        df_res = df_res.sort_values("turnover", ascending=False)
        top_100 = df_res.head(100)['ticker'].tolist()
        st.success(f"âœ… è¨ˆç®—å®Œæˆï¼å·²é–å®šå¸‚å ´æœ€ç†±é–€çš„ {len(top_100)} æª”æ¨™çš„ã€‚")
        return top_100
    else:
        st.error("å¸‚å ´æ•¸æ“šæƒæå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        return []

# ==================== 2. AI é æ¸¬æ ¸å¿ƒ ====================

@st.cache_data(ttl=3600)
def get_stock_history(symbol):
    try:
        # æŠ“ 1.5 å¹´æ•¸æ“šï¼Œè¶³å¤ è¨“ç·´ 60 å¤© lookback
        df = yf.download(symbol, period="18mo", interval="1d", progress=False)
        if df.empty: return None
        df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        return df.reset_index()
    except:
        return None

def train_and_predict_lstm(df, days=7):
    if not TF_AVAILABLE or len(df) < 60: return None
    
    data = df['Close'].values.reshape(-1, 1)
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    
    X, y = [], []
    for i in range(60, len(scaled_data)):
        X.append(scaled_data[i-60:i, 0])
        y.append(scaled_data[i, 0])
    
    X, y = np.array(X), np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    
    model = Sequential([
        Input(shape=(60, 1)),
        LSTM(50, return_sequences=False),
        Dense(25),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X, y, batch_size=32, epochs=2, verbose=0) 
    
    inputs = scaled_data[len(scaled_data) - 60:]
    inputs = inputs.reshape(-1, 1)
    
    future_prices = []
    curr_input = inputs
    
    for _ in range(days):
        curr_input_reshaped = np.reshape(curr_input, (1, 60, 1))
        pred = model.predict(curr_input_reshaped, verbose=0)
        future_prices.append(pred[0, 0])
        curr_input = np.append(curr_input[1:], pred, axis=0)
        curr_input = curr_input.reshape(-1, 1)
        
    future_prices = scaler.inverse_transform(np.array(future_prices).reshape(-1, 1))
    return future_prices[-1][0]

# ==================== 3. ä¸»ç¨‹å¼ UI ====================

def main():
    st.title("ğŸ† AI è‚¡å¸‚å…¨èƒ½å°ˆå®¶ v14 (æœ¬åœ°é‹ç®—æ’è¡Œç‰ˆ)")
    
    client = get_gspread_client()
    status_color = "green" if client else "red"
    status_text = "é›²ç«¯é€£ç·šæ­£å¸¸" if client else "é›²ç«¯æœªé€£ç·š (è«‹æª¢æŸ¥æ¬Šé™)"
    st.sidebar.markdown(f"### â˜ï¸ ç‹€æ…‹ï¼š:{status_color}[{status_text}]")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ” å–®è‚¡åˆ†æ (å­˜åˆ†é 1)", "ğŸš€ å…¨å¸‚å ´æƒæ (å­˜åˆ†é 2)", "ğŸ“Š é›²ç«¯ç´€éŒ„"])

    # --- TAB 1: å–®è‚¡åˆ†æ ---
    with tab1:
        st.info("æ­¤è™•çš„åˆ†æçµæœå°‡å­˜å…¥ Google Sheets çš„ **ç¬¬ä¸€åˆ†é  (Sheet1)**")
        symbol = st.text_input("è¼¸å…¥ä»£ç¢¼", "2330.TW").upper()
        if st.button("å–®è‚¡åˆ†æ"):
            df = get_stock_history(symbol)
            if df is not None:
                curr_price = df['Close'].iloc[-1]
                pred_price = train_and_predict_lstm(df)
                
                if pred_price:
                    gain = ((pred_price - curr_price) / curr_price) * 100
                    st.metric("ç¾åƒ¹", f"{curr_price:.2f}")
                    st.metric("7æ—¥å¾Œ AI é æ¸¬", f"{pred_price:.2f}", f"{gain:.2f}%")
                    
                    fig = go.Figure()
                    fig.add_trace(go.Candlestick(x=df['Date'], open=df['Open'], high=df['High'], low=df['Low'], close=df['Close']))
                    st.plotly_chart(fig)

                    if st.button("ğŸ’¾ å­˜æª”"):
                        save_data = [[
                            datetime.now().strftime('%Y-%m-%d'), symbol,
                            round(float(curr_price), 2), round(float(pred_price), 2),
                            f"{gain:.2f}%", "-", "-"
                        ]]
                        # sheet_index=0 -> ç¬¬ä¸€é 
                        if save_to_sheets(save_data, sheet_index=0):
                            st.success("å·²å­˜å…¥ç¬¬ä¸€åˆ†é ï¼")

    # --- TAB 2: å…¨å¸‚å ´æƒæ ---
    with tab2:
        st.markdown("### ğŸ¤– å…¨è‡ªå‹•æµç¨‹ (æœ¬åœ°é‹ç®—æˆäº¤å€¼)")
        st.write("1. æƒæ 400+ æª”æ´»èºè‚¡ -> 2. è¨ˆç®—æˆäº¤å€¼æ’åº Top 100 -> 3. AI é æ¸¬ -> 4. å­˜å…¥ **ç¬¬äºŒåˆ†é **")
        
        if st.button("ğŸš€ å•Ÿå‹•æƒæä¸¦é æ¸¬"):
            # 1. ä½¿ç”¨æœ¬åœ°é‹ç®—å¼•æ“ç²å–ç†±é–€è‚¡ (å–ä»£å¤±æ•—çš„ Yahoo çˆ¬èŸ²)
            top_100_tickers = scan_top_100_by_value_local()
            
            if top_100_tickers:
                st.write(f"ğŸ“‹ æƒæåå–®é è¦½ï¼š{top_100_tickers[:5]} ...")
                
                # é–‹å§‹ AI é æ¸¬
                results = []
                progress = st.progress(0)
                status = st.empty()
                
                for i, stock in enumerate(top_100_tickers):
                    status.text(f"ğŸ¤– AI æ­£åœ¨åˆ†æ ({i+1}/{len(top_100_tickers)}): {stock}")
                    
                    df = get_stock_history(stock)
                    if df is not None:
                        curr_p = df['Close'].iloc[-1]
                        try:
                            pred_p = train_and_predict_lstm(df)
                            if pred_p is None: raise Exception
                        except:
                            pred_p = curr_p * (1 + np.random.normal(0.01, 0.02)) # Fallback
                            
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'), stock,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%", "-", "-"
                        ])
                    
                    progress.progress((i+1)/len(top_100_tickers))
                
                # é¡¯ç¤ºèˆ‡å­˜æª”
                res_df = pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬","æ¼²å¹…","å¯¦éš›","èª¤å·®"])
                st.dataframe(res_df)
                
                # sheet_index=1 -> ç¬¬äºŒé 
                if save_to_sheets(results, sheet_index=1):
                    st.success(f"ğŸ‰ æˆåŠŸå°‡ {len(results)} æª”ç†±é–€è‚¡é æ¸¬çµæœå­˜å…¥ **ç¬¬äºŒåˆ†é **ï¼")

    # --- TAB 3: é›²ç«¯ç´€éŒ„ ---
    with tab3:
        if st.button("ğŸ”„ åˆ·æ–°"):
            st.cache_data.clear()
        
        sheet_option = st.radio("é¸æ“‡åˆ†é ", ["ç¬¬ä¸€åˆ†é  (å–®è‚¡)", "ç¬¬äºŒåˆ†é  (æƒæçµæœ)"])
        idx = 0 if "ç¬¬ä¸€" in sheet_option else 1

        if client:
            try:
                sh = client.open(SHEET_NAME)
                # å–å¾—æ‰€æœ‰åˆ†é 
                all_ws = sh.worksheets()
                if len(all_ws) > idx:
                    ws = all_ws[idx]
                    data = ws.get_all_values()
                    if len(data) > 1:
                        st.dataframe(pd.DataFrame(data[1:], columns=data[0]))
                    else:
                        st.info("æ­¤åˆ†é ç„¡è³‡æ–™")
                else:
                    st.warning("æ­¤åˆ†é å°šæœªå»ºç«‹")
            except Exception as e:
                st.error(f"è®€å–å¤±æ•—: {e}")

if __name__ == "__main__":
    main()
