import streamlit as st

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚é æ¸¬å°ˆå®¶ Pro v4", layout="wide")

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3

# åœç”¨ SSL è­¦å‘Š (é‡å°è­‰äº¤æ‰€ API)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¼‰å…¥å¿…è¦åº«
try:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import tensorflow as tf
    from sklearn.preprocessing import MinMaxScaler
except ImportError:
    st.error("ç¼ºå°‘å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install gspread oauth2client tensorflow scikit-learn urllib3 certifi")

# --- å…¨å±€è¨­å®š ---
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History" 
BATCH_CD = 1.2 # é˜²æ­¢è¢« yfinance å°é–çš„å»¶é²

# ==================== 1. æ•¸æ“šç²å– (è§£æ±º KeyError èˆ‡ ç›¤ä¸­æŠ“ä¸åˆ°å•é¡Œ) ====================

def get_top_100_value_stocks():
    """è‡ªå‹•åˆ¤æ–·æ™‚é–“ï¼šç¢ºä¿æŠ“åˆ°æœ€è¿‘çš„æœ‰è³‡æ–™äº¤æ˜“æ—¥"""
    now = datetime.now()
    
    # å¦‚æœé‚„æ²’åˆ°ä¸‹åˆ 3:00 (çµç®—å®Œæˆæ™‚é–“)ï¼Œå…ˆå¾æ˜¨å¤©é–‹å§‹æ‰¾
    if now.hour < 15:
        target_date = now - timedelta(days=1)
    else:
        target_date = now

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    
    attempts = 0
    final_df = pd.DataFrame()
    
    # å¾€å‰æœå°‹æœ€å¤š 10 å¤©ï¼Œç›´åˆ°æŠ“åˆ°çœŸæ­£çš„æ•¸æ“š
    while attempts < 10:
        date_str = target_date.strftime('%Y%m%d')
        url = f"https://www.twse.com.tw/exchangeReport/MI_INDEX?response=json&date={date_str}&type=ALLBUT0999"
        
        try:
            res = requests.get(url, headers=headers, timeout=15, verify=False)
            data = res.json()
            
            # åˆ¤æ–·æ¨™ç±¤æ˜¯å¦å­˜åœ¨ (ä¿®æ­£ KeyError çš„æ ¸å¿ƒ)
            target_key = 'data9' if 'data9' in data else 'data8'
            
            if data.get('stat') == "OK" and target_key in data:
                fields_key = 'fields9' if 'fields9' in data else 'fields8'
                df = pd.DataFrame(data[target_key], columns=data[fields_key])
                
                # è³‡æ–™æ¸…æ´—ï¼šå»é™¤æ•¸å­—ä¸­çš„é€—è™Ÿ
                df['æˆäº¤é‡‘é¡'] = df['æˆäº¤é‡‘é¡'].str.replace(',', '').astype(float)
                df['è­‰åˆ¸ä»£è™Ÿ'] = df['è­‰åˆ¸ä»£è™Ÿ'] + ".TW"
                
                st.info(f"ğŸ“… æ•¸æ“šæŠ“å–æˆåŠŸï¼ä¾†æºæ—¥æœŸ: {target_date.strftime('%Y-%m-%d')}")
                return df.nlargest(100, 'æˆäº¤é‡‘é¡')[['è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', 'æ”¶ç›¤åƒ¹']]
            
        except Exception:
            pass # ç•¥ééŒ¯èª¤ï¼Œå˜—è©¦å‰ä¸€å¤©
        
        target_date -= timedelta(days=1)
        attempts += 1

    st.error("âŒ ç„¡æ³•ç²å–å°è‚¡ç™¾å¤§æ’åï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ–ç¢ºèªæ˜¯å¦ç‚ºé€£çºŒé•·å‡ã€‚")
    return pd.DataFrame()

def get_stock_data(symbol, period="1y"):
    """ç²å–å–®è‚¡æ­·å²æ•¸æ“š"""
    try:
        df = yf.download(symbol, period=period, interval="1d", progress=False)
        if df.empty: return None
        df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        return df.reset_index()
    except:
        return None

# ==================== 2. é›²ç«¯åŒæ­¥æ¨¡çµ„ ====================

def get_gspread_client():
    if not os.path.exists(CREDENTIALS_JSON):
        st.warning(f"âš ï¸ æ‰¾ä¸åˆ°æ†‘è­‰æª”æ¡ˆ {CREDENTIALS_JSON}ã€‚")
        return None
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_JSON, scope)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"âŒ Google Sheets é€£æ¥å¤±æ•—: {e}")
        return None

def save_to_sheets(new_data):
    client = get_gspread_client()
    if client:
        try:
            sh = client.open(SHEET_NAME)
            ws = sh.sheet1
            # åˆå§‹åŒ–æ¨™é¡Œ
            if ws.row_count <= 1 and (not ws.cell(1, 1).value):
                ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
            ws.append_rows(new_data)
            return True
        except Exception as e:
            st.error(f"âŒ é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
    return False

# ==================== 3. æ©Ÿå™¨å­¸ç¿’æ¨è«–æ¨¡çµ„ ====================

@st.cache_resource
def get_trained_base_model():
    """å»ºç«‹åŸºç¤åŸºæº–æ¨¡å‹ï¼ˆä½¿ç”¨ 2330 ä½œç‚ºæ¬Šé‡ç¯„æœ¬ï¼‰"""
    df = get_stock_data("2330.TW")
    if df is None: return None
    
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    
    X, y = [], []
    for i in range(60, len(scaled)):
        X.append(scaled[i-60:i, 0])
        y.append(scaled[i, 0])
    
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(60, 1)),
        tf.keras.layers.LSTM(50),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(np.array(X), np.array(y), epochs=3, batch_size=32, verbose=0)
    return model

def fast_predict(model, df):
    """åŸºæº–æ¨¡å‹å¿«é€Ÿæ¨è«–"""
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    last_60 = scaled[-60:].reshape(1, 60, 1)
    pred = model.predict(last_60, verbose=0)
    return scaler.inverse_transform(pred)[0][0]

# ==================== 4. ä¸»ä»‹é¢é‚è¼¯ ====================

def main():
    st.title("ğŸ“ˆ AI è‚¡å¸‚è¶¨å‹¢åˆ†æèˆ‡é›²ç«¯å­˜æª”ç³»çµ±")
    
    tab1, tab2 = st.tabs(["ğŸš€ ç™¾å¤§è‡ªå‹•é æ¸¬", "ğŸ§ æ­·å²åæ€èˆ‡å­¸ç¿’"])

    with tab1:
        st.markdown("### è‡ªå‹•æŠ“å–æˆäº¤å€¼å‰ 100 åä¸¦é€²è¡Œ 7 æ—¥é æ¸¬")
        if st.button("åŸ·è¡Œå…¨è‡ªå‹•æ‰¹æ¬¡åˆ†æ"):
            with st.spinner("ğŸ” æ­£åœ¨æª¢ç´¢è­‰äº¤æ‰€æ•¸æ“š..."):
                top_100 = get_top_100_value_stocks()
                model = get_trained_base_model()
            
            if not top_100.empty and model:
                results = []
                bar = st.progress(0)
                msg = st.empty()
                
                for i, row in top_100.iterrows():
                    symbol = row['è­‰åˆ¸ä»£è™Ÿ']
                    msg.text(f"åˆ†æé€²åº¦ ({i+1}/100): {symbol}")
                    
                    time.sleep(BATCH_CD) # CD ç·©è¡
                    df = get_stock_data(symbol)
                    
                    if df is not None and len(df) >= 60:
                        curr_p = df['Close'].iloc[-1]
                        pred_p = fast_predict(model, df)
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'),
                            symbol,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%",
                            "-", "-" # é ç•™çµ¦ 7 å¤©å¾Œçš„å¯¦éš›å€¼
                        ])
                    bar.progress((i+1)/100)
                
                if save_to_sheets(results):
                    st.success("ğŸ‰ åˆ†æå®Œæˆï¼æ‰€æœ‰æ•¸æ“šå·²åŒæ­¥è‡³ Google é›²ç«¯è©¦ç®—è¡¨ã€‚")
                    st.dataframe(pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬åƒ¹","æ¼²å¹…","å¯¦éš›","èª¤å·®"]))

    with tab2:
        st.subheader("Google Sheets æ­·å²ç´€éŒ„åæ€")
        client = get_gspread_client()
        if client:
            try:
                ws = client.open(SHEET_NAME).sheet1
                records = ws.get_all_records()
                if records:
                    st.write("ğŸ“Š é›²ç«¯å„²å­˜çš„æœ€è¿‘é æ¸¬ï¼š")
                    st.dataframe(pd.DataFrame(records).tail(20))
                else:
                    st.info("é›²ç«¯ç›®å‰å°šç„¡é æ¸¬ç´€éŒ„ã€‚")
            except Exception as e:
                st.error(f"è®€å–é›²ç«¯ç´€éŒ„å¤±æ•—: {e}")

if __name__ == "__main__":
    main()
