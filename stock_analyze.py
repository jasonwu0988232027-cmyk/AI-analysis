import streamlit as st

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚é æ¸¬å°ˆå®¶ Pro v6 (ç©©å®šç‰ˆ)", layout="wide")

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3

# åœç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¼‰å…¥å¿…è¦åº«
try:
    import gspread
    from oauth2client.service_account import ServiceAccountCredentials
    import tensorflow as tf
    from sklearn.preprocessing import MinMaxScaler
except ImportError:
    st.error("ç¼ºå°‘å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼špip install gspread oauth2client tensorflow scikit-learn urllib3 certifi")

# --- å…¨å±€è¨­å®š ---
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History" 
BATCH_CD = 1.0 # ç¨å¾®åŠ å¿«é€Ÿåº¦

# ==================== 1. ç©©å®šç‰ˆç™¾å¤§åå–® (ä¸ä¾è³´è­‰äº¤æ‰€ API) ====================

def get_stable_stock_list():
    """ç›´æ¥å›å‚³å…§å»ºçš„ç†±é–€å°è‚¡åå–®ï¼Œä¿è­‰ä¸ç¼ºè³‡æ–™"""
    # é€™æ˜¯å°ç£ 50 + ç†±é–€é›»å­/é‡‘è/å‚³ç”¢è‚¡çš„ç¶œåˆåå–®
    tickers = [
        '2330.TW', '2317.TW', '2454.TW', '2308.TW', '2382.TW', '2303.TW', '2881.TW', '2882.TW', '2891.TW', '2886.TW',
        '2412.TW', '2884.TW', '1216.TW', '2885.TW', '3711.TW', '2892.TW', '2357.TW', '2880.TW', '2890.TW', '5880.TW',
        '2345.TW', '3008.TW', '2327.TW', '2395.TW', '2883.TW', '2887.TW', '3045.TW', '4938.TW', '2408.TW', '1101.TW',
        '2002.TW', '3037.TW', '2379.TW', '3034.TW', '2603.TW', '2609.TW', '2615.TW', '3231.TW', '2356.TW', '2301.TW',
        '2801.TW', '2888.TW', '6669.TW', '6415.TW', '3035.TW', '3017.TW', '4904.TW', '5871.TW', '2912.TW', '9910.TW',
        '1301.TW', '1303.TW', '1326.TW', '6505.TW', '2353.TW', '2409.TW', '3481.TW', '6770.TW', '1513.TW', '1519.TW',
        '1605.TW', '2371.TW', '2383.TW', '2388.TW', '2451.TW', '2474.TW', '3019.TW', '3042.TW', '3044.TW', '3189.TW',
        '3293.TW', '3529.TW', '3532.TW', '3533.TW', '3653.TW', '3661.TW', '3702.TW', '4919.TW', '4958.TW', '4961.TW'
    ]
    
    # å»ºç«‹ DataFrame çµæ§‹
    data = {'è­‰åˆ¸ä»£è™Ÿ': tickers, 'è­‰åˆ¸åç¨±': [f"è‚¡ç¥¨ {t}" for t in tickers]} 
    df = pd.DataFrame(data)
    return df

def get_stock_data(symbol, period="1y"):
    """ç²å–å–®è‚¡æ­·å²æ•¸æ“š"""
    try:
        df = yf.download(symbol, period=period, interval="1d", progress=False)
        if df.empty: return None
        df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        return df.reset_index()
    except:
        return None

# ==================== 2. é›²ç«¯åŒæ­¥æ¨¡çµ„ (å®¹éŒ¯ç‰ˆ) ====================

def get_gspread_client():
    if not os.path.exists(CREDENTIALS_JSON):
        # é€™è£¡ä¸å ±éŒ¯ï¼Œæ”¹ç”¨å›å‚³ Noneï¼Œè®“ç¨‹å¼çŸ¥é“æ²’é‘°åŒ™å°±å¥½
        return None
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_JSON, scope)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"âŒ Google Sheets é€£æ¥å¤±æ•—: {e}")
        return None

def save_to_sheets(new_data):
    client = get_gspread_client()
    if client is None:
        st.warning("âš ï¸ æœªåµæ¸¬åˆ°æ†‘è­‰ (credentials.json)ï¼Œæœ¬æ¬¡é æ¸¬çµæœå°‡**ä¸æœƒ**ä¸Šå‚³è‡³é›²ç«¯ï¼Œåƒ…é¡¯ç¤ºæ–¼ä¸‹æ–¹ã€‚")
        return False
        
    try:
        sh = client.open(SHEET_NAME)
        ws = sh.sheet1
        if ws.row_count <= 1 and (not ws.cell(1, 1).value):
            ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
        ws.append_rows(new_data)
        st.success("âœ… é›²ç«¯å­˜æª”æˆåŠŸï¼")
        return True
    except Exception as e:
        st.error(f"âŒ é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
        return False

# ==================== 3. æ©Ÿå™¨å­¸ç¿’æ¨è«–æ¨¡çµ„ ====================

@st.cache_resource
def get_trained_base_model():
    """å»ºç«‹åŸºç¤åŸºæº–æ¨¡å‹"""
    df = get_stock_data("2330.TW")
    if df is None: 
        st.error("ç„¡æ³•ä¸‹è¼‰å°ç©é›»æ•¸æ“šä½œç‚ºåŸºæº–ï¼Œè«‹æª¢æŸ¥ç¶²è·¯ã€‚")
        return None
    
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    
    X, y = [], []
    for i in range(60, len(scaled)):
        X.append(scaled[i-60:i, 0])
        y.append(scaled[i, 0])
    
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(60, 1)),
        tf.keras.layers.LSTM(50),
        tf.keras.layers.Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    model.fit(np.array(X), np.array(y), epochs=3, batch_size=32, verbose=0)
    return model

def fast_predict(model, df):
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df[['Close']].values)
    last_60 = scaled[-60:].reshape(1, 60, 1)
    pred = model.predict(last_60, verbose=0)
    return scaler.inverse_transform(pred)[0][0]

# ==================== 4. ä¸»ä»‹é¢ ====================

def main():
    st.title("ğŸ“ˆ AI è‚¡å¸‚è¶¨å‹¢åˆ†æ Pro (v6 ç©©å®šç‰ˆ)")
    
    tab1, tab2 = st.tabs(["ğŸš€ ç†±é–€è‚¡æ‰¹é‡é æ¸¬", "ğŸ§ æ­·å²åæ€"])

    with tab1:
        st.info("ç³»çµ±æ¡ç”¨ã€Œå…§å»ºç†±é–€è‚¡åå–® (80+)ã€ï¼Œä¸å†å—è­‰äº¤æ‰€é€£ç·šé™åˆ¶ï¼Œä¿è­‰åŸ·è¡Œé †æš¢ã€‚")
        
        if st.button("é–‹å§‹åŸ·è¡Œé æ¸¬"):
            with st.spinner("æ¨¡å‹åˆå§‹åŒ–ä¸­..."):
                # ç›´æ¥ä½¿ç”¨ç©©å®šåå–®ï¼Œä¸å†å»è­‰äº¤æ‰€å†’éšª
                target_stocks = get_stable_stock_list()
                model = get_trained_base_model()
            
            if not target_stocks.empty and model:
                results = []
                bar = st.progress(0)
                msg = st.empty()
                
                total = len(target_stocks)
                for i, row in target_stocks.iterrows():
                    symbol = row['è­‰åˆ¸ä»£è™Ÿ']
                    msg.text(f"æ­£åœ¨é‹ç®— ({i+1}/{total}): {symbol}")
                    
                    # é€Ÿåº¦ç¨å¾®åŠ å¿«ï¼Œå› ç‚ºå…§å»ºåå–®å¾ˆç©©
                    time.sleep(0.5) 
                    df = get_stock_data(symbol)
                    
                    if df is not None and len(df) >= 60:
                        curr_p = df['Close'].iloc[-1]
                        pred_p = fast_predict(model, df)
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'),
                            symbol,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%",
                            "-", "-"
                        ])
                    bar.progress((i+1)/total)
                
                # é¡¯ç¤ºçµæœ DataFrame
                res_df = pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬åƒ¹","æ¼²å¹…","å¯¦éš›","èª¤å·®"])
                st.dataframe(res_df)
                
                # å˜—è©¦å­˜æª” (å¦‚æœæ²’é‘°åŒ™ï¼Œæœƒè‡ªå‹•è·³éä¸¦é¡¯ç¤ºè­¦å‘Šï¼Œä¸æœƒå ±éŒ¯)
                save_to_sheets(results)

    with tab2:
        st.subheader("Google Sheets æ­·å²ç´€éŒ„")
        client = get_gspread_client()
        if client:
            try:
                ws = client.open(SHEET_NAME).sheet1
                records = ws.get_all_records()
                if records:
                    st.dataframe(pd.DataFrame(records).tail(20))
                else:
                    st.info("æš«ç„¡ç´€éŒ„")
            except Exception as e:
                st.error(f"è®€å–å¤±æ•—: {e}")
        else:
            st.info("è«‹ä¸Šå‚³ credentials.json ä»¥å•Ÿç”¨æ­·å²å›æ¸¬åŠŸèƒ½ã€‚")

if __name__ == "__main__":
    main()
