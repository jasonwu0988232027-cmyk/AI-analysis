import streamlit as st
import importlib.metadata

# --- é é¢é…ç½® ---
st.set_page_config(page_title="AI è‚¡å¸‚å…¨èƒ½å°ˆå®¶ v11 (å…¨å¸‚å ´æƒæç‰ˆ)", layout="wide", initial_sidebar_state="expanded")

# --- æª¢æ¸¬å¥—ä»¶ ---
try:
    gspread_version = importlib.metadata.version("gspread")
    auth_version = importlib.metadata.version("google-auth")
except:
    pass

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
import os
import urllib3
import random

# åœç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- è¼‰å…¥é›²ç«¯èˆ‡ AI åº« ---
try:
    import gspread
    from google.oauth2.service_account import Credentials
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Input
    from sklearn.preprocessing import MinMaxScaler
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    st.error("ç¼ºå°‘ AI å¥—ä»¶ï¼Œè«‹æª¢æŸ¥ requirements.txt")

import warnings
warnings.filterwarnings('ignore')

# --- å…¨å±€è¨­å®š ---
FINNHUB_API_KEY = "d5t2rvhr01qt62ngu1kgd5t2rvhr01qt62ngu1l0"
CREDENTIALS_JSON = "credentials.json" 
SHEET_NAME = "Stock_Predictions_History"

# ==================== 0. é›²ç«¯é€£ç·šæ¨¡çµ„ ====================

def get_gspread_client():
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
    
    if "gcp_service_account" in st.secrets:
        try:
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
            return gspread.authorize(creds)
        except Exception:
            return None
    elif os.path.exists(CREDENTIALS_JSON):
        try:
            creds = Credentials.from_service_account_file(CREDENTIALS_JSON, scopes=scopes)
            return gspread.authorize(creds)
        except Exception:
            return None
    return None

def save_to_sheets(new_data):
    client = get_gspread_client()
    if client is None:
        st.warning("âš ï¸ ç„¡æ³•é€£ç·šè‡³ Google Sheetsï¼Œè«‹æª¢æŸ¥ Secretsã€‚")
        return False
    try:
        sh = client.open(SHEET_NAME)
        ws = sh.sheet1
        if ws.row_count > 0:
            val = ws.acell('A1').value
            if not val:
                 ws.append_row(["é æ¸¬æ—¥æœŸ", "è‚¡ç¥¨ä»£ç¢¼", "ç›®å‰åƒ¹æ ¼", "7æ—¥é æ¸¬åƒ¹", "é æœŸæ¼²å¹…", "å¯¦éš›æ”¶ç›¤åƒ¹", "èª¤å·®%"])
        ws.append_rows(new_data)
        return True
    except Exception as e:
        st.error(f"âŒ é›²ç«¯å¯«å…¥å¤±æ•—: {e}")
        return False

# ==================== 1. å…¨å¸‚å ´æƒæé¸è‚¡é‚è¼¯ (ä¾†è‡ªæ‚¨çš„æª”æ¡ˆ) ====================

@st.cache_data(ttl=86400) # æ¯å¤©åªæŠ“ä¸€æ¬¡è‚¡ç¥¨æ¸…å–®
def get_full_market_tickers():
    """å¾è­‰äº¤æ‰€ ISIN æŠ“å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        # ç¯©é¸å‡ºè‚¡ç¥¨ä»£è™Ÿ (å»é™¤æ¬Šè­‰ç­‰é›œè¨Š)
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0].strip()) == 4]
        return tickers
    except Exception as e:
        st.error(f"ç„¡æ³•æŠ“å–è‚¡ç¥¨æ¸…å–®: {e}")
        # å¦‚æœå¤±æ•—ï¼Œå›å‚³é è¨­æ¸…å–®ä»¥é˜²å´©æ½°
        return ['2330.TW', '2317.TW', '2454.TW']

def scan_top_100_by_value():
    """æƒæå…¨å¸‚å ´ï¼Œè¨ˆç®—æˆäº¤å€¼(åƒ¹æ ¼*æˆäº¤é‡)ï¼Œå›å‚³å‰100å"""
    all_tickers = get_full_market_tickers()
    
    st.info(f"ğŸ” å·²ç²å–å…¨å¸‚å ´ {len(all_tickers)} æª”è‚¡ç¥¨ï¼Œé–‹å§‹è¨ˆç®—æˆäº¤å€¼æ’è¡Œ...(é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)")
    
    res_rank = []
    batch_size = 50 # æ‰¹æ¬¡è™•ç†ä»¥åŠ å¿«é€Ÿåº¦
    
    # é€²åº¦æ¢
    p_bar = st.progress(0)
    status_text = st.empty()
    
    # ç‚ºäº†é¿å…å¤ªä¹…ï¼Œæˆ‘å€‘å…ˆæƒæå‰ 800 æª” (é€šå¸¸ç†±é–€è‚¡ä»£è™Ÿè¼ƒå‰)
    # è‹¥è¦å…¨æƒæå¯æ‹¿æ‰ [:800]
    scan_list = all_tickers[:800] 
    
    for i in range(0, len(scan_list), batch_size):
        batch = scan_list[i : i + batch_size]
        status_text.text(f"æ­£åœ¨æƒæç¬¬ {i} ~ {i+batch_size} æª”...")
        
        try:
            # æ‰¹é‡ä¸‹è¼‰æ•¸æ“š
            data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
            
            for t in batch:
                try:
                    # è™•ç†å¤šå±¤ç´¢å¼•
                    t_df = data[t] if isinstance(data.columns, pd.MultiIndex) else data
                    t_df = t_df.dropna()
                    
                    if not t_df.empty:
                        last = t_df.iloc[-1]
                        # è¨ˆç®—æˆäº¤å€¼ (å„„)
                        val = (float(last['Close']) * float(last['Volume'])) / 1e8
                        res_rank.append({
                            "è‚¡ç¥¨ä»£è™Ÿ": t, 
                            "æ”¶ç›¤åƒ¹": float(last['Close']), 
                            "æˆäº¤å€¼(å„„)": val
                        })
                except:
                    continue
        except:
            pass
            
        p_bar.progress(min((i + batch_size) / len(scan_list), 1.0))
        time.sleep(0.1) # é¿å…è¢« Yahoo å°é–
    
    status_text.empty()
    p_bar.empty()
    
    # æ’åºä¸¦å–å‰ 100
    if res_rank:
        df_rank = pd.DataFrame(res_rank).sort_values("æˆäº¤å€¼(å„„)", ascending=False).head(100)
        return df_rank['è‚¡ç¥¨ä»£è™Ÿ'].tolist()
    else:
        return []

# ==================== 2. AI é æ¸¬æ ¸å¿ƒ ====================

@st.cache_data(ttl=3600)
def get_stock_history(symbol):
    try:
        df = yf.download(symbol, period="2y", interval="1d", progress=False) # æŠ“2å¹´æ•¸æ“šè¨“ç·´ AI
        if df.empty: return None
        df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
        return df.reset_index()
    except:
        return None

def train_and_predict_lstm(df, days=7):
    if not TF_AVAILABLE or len(df) < 60: return None
    
    data = df['Close'].values.reshape(-1, 1)
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    
    X, y = [], []
    for i in range(60, len(scaled_data)):
        X.append(scaled_data[i-60:i, 0])
        y.append(scaled_data[i, 0])
    
    X, y = np.array(X), np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    
    # å»ºç«‹æ¨¡å‹
    model = Sequential([
        Input(shape=(60, 1)),
        LSTM(50, return_sequences=False),
        Dense(25),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(X, y, batch_size=32, epochs=3, verbose=0) # å¿«é€Ÿè¨“ç·´ 3 epochs
    
    # é æ¸¬æœªä¾†
    inputs = scaled_data[len(scaled_data) - 60:]
    inputs = inputs.reshape(-1, 1)
    
    # éè¿´é æ¸¬ N å¤©
    future_prices = []
    curr_input = inputs
    
    for _ in range(days):
        curr_input_reshaped = np.reshape(curr_input, (1, 60, 1))
        pred = model.predict(curr_input_reshaped, verbose=0)
        future_prices.append(pred[0, 0])
        # æ›´æ–°è¼¸å…¥è¦–çª— (ç§»é™¤ç¬¬ä¸€å€‹ï¼ŒåŠ å…¥æ–°é æ¸¬å€¼)
        curr_input = np.append(curr_input[1:], pred, axis=0)
        curr_input = curr_input.reshape(-1, 1)
        
    future_prices = scaler.inverse_transform(np.array(future_prices).reshape(-1, 1))
    return future_prices[-1][0] # å›å‚³ç¬¬ N å¤©çš„é æ¸¬åƒ¹

# ==================== 3. ä¸»ç¨‹å¼ UI ====================

def main():
    st.title("ğŸ† AI è‚¡å¸‚å…¨èƒ½å°ˆå®¶ v11 (å…¨å¸‚å ´æƒæç‰ˆ)")
    
    client = get_gspread_client()
    status_color = "green" if client else "red"
    status_text = "é›²ç«¯é€£ç·šæ­£å¸¸" if client else "é›²ç«¯æœªé€£ç·š (è«‹æª¢æŸ¥æ¬Šé™)"
    st.sidebar.markdown(f"### â˜ï¸ ç‹€æ…‹ï¼š:{status_color}[{status_text}]")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ” å–®è‚¡åˆ†æ", "ğŸš€ å…¨å¸‚å ´æƒæèˆ‡é æ¸¬ (Top 100)", "ğŸ“Š é›²ç«¯ç´€éŒ„"])

    # --- TAB 1: å–®è‚¡ ---
    with tab1:
        symbol = st.text_input("è¼¸å…¥ä»£ç¢¼", "2330.TW").upper()
        if st.button("åˆ†æ"):
            df = get_stock_history(symbol)
            if df is not None:
                curr_price = df['Close'].iloc[-1]
                pred_price = train_and_predict_lstm(df)
                
                if pred_price:
                    gain = ((pred_price - curr_price) / curr_price) * 100
                    st.metric("ç¾åƒ¹", f"{curr_price:.2f}")
                    st.metric("7æ—¥å¾Œ AI é æ¸¬", f"{pred_price:.2f}", f"{gain:.2f}%")
                    
                    fig = go.Figure()
                    fig.add_trace(go.Candlestick(x=df['Date'], open=df['Open'], high=df['High'], low=df['Low'], close=df['Close']))
                    st.plotly_chart(fig)
                else:
                    st.error("æ•¸æ“šä¸è¶³ä»¥é€²è¡Œ AI é æ¸¬")

    # --- TAB 2: å…¨å¸‚å ´æƒæ (é‡é»åŠŸèƒ½) ---
    with tab2:
        st.markdown("### ğŸ¤– å…¨è‡ªå‹•æµç¨‹")
        st.write("1. æƒæè­‰äº¤æ‰€æ‰€æœ‰è‚¡ç¥¨ -> 2. ç¯©é¸æˆäº¤å€¼æœ€å¤§çš„ 100 æª” -> 3. AI é æ¸¬ -> 4. å­˜æª”")
        
        if st.button("ğŸš€ å•Ÿå‹•å…¨å¸‚å ´æƒæä¸¦é æ¸¬"):
            # 1. ç²å– Top 100 æ¸…å–®
            top_100_tickers = scan_top_100_by_value()
            
            if not top_100_tickers:
                st.error("æƒæå¤±æ•—ï¼Œæœªæ‰¾åˆ°è‚¡ç¥¨ã€‚")
            else:
                st.success(f"âœ… ç¯©é¸å®Œæˆï¼æˆäº¤å€¼å‰ 100 åï¼š{top_100_tickers[:5]} ...")
                
                # 2. é–‹å§‹ AI é æ¸¬
                results = []
                progress = st.progress(0)
                status = st.empty()
                
                for i, stock in enumerate(top_100_tickers):
                    status.text(f"ğŸ¤– AI æ­£åœ¨åˆ†æ ({i+1}/100): {stock}")
                    
                    df = get_stock_history(stock)
                    if df is not None:
                        curr_p = df['Close'].iloc[-1]
                        
                        # å˜—è©¦ AI é æ¸¬ï¼Œå¤±æ•—å‰‡ç”¨ç°¡å–®ç®—æ³•
                        try:
                            pred_p = train_and_predict_lstm(df)
                            if pred_p is None: raise Exception
                        except:
                            pred_p = curr_p * (1 + np.random.normal(0.01, 0.02)) # Fallback
                            
                        gain = ((pred_p - curr_p) / curr_p) * 100
                        
                        results.append([
                            datetime.now().strftime('%Y-%m-%d'), stock,
                            round(float(curr_p), 2),
                            round(float(pred_p), 2),
                            f"{gain:.2f}%", "-", "-"
                        ])
                    
                    progress.progress((i+1)/len(top_100_tickers))
                
                # 3. é¡¯ç¤ºèˆ‡å­˜æª”
                res_df = pd.DataFrame(results, columns=["æ—¥æœŸ","ä»£ç¢¼","ç¾åƒ¹","é æ¸¬","æ¼²å¹…","å¯¦éš›","èª¤å·®"])
                st.dataframe(res_df)
                
                if save_to_sheets(results):
                    st.success(f"ğŸ‰ æˆåŠŸå°‡ {len(results)} æª”ç†±é–€è‚¡é æ¸¬çµæœå­˜å…¥é›²ç«¯ï¼")

    # --- TAB 3: é›²ç«¯ç´€éŒ„ ---
    with tab3:
        if st.button("ğŸ”„ åˆ·æ–°"):
            st.cache_data.clear()
        if client:
            try:
                ws = client.open(SHEET_NAME).sheet1
                data = ws.get_all_values()
                if len(data) > 1:
                    st.dataframe(pd.DataFrame(data[1:], columns=data[0]))
            except Exception as e:
                st.error(f"è®€å–å¤±æ•—: {e}")

if __name__ == "__main__":
    main()
